# Install and import NLTK
!pip install nltk

import nltk
import string
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from nltk import pos_tag

# Download required NLTK resources
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('averaged_perceptron_tagger')

# Input text
text = "It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife."

# Convert text to lowercase
text = text.lower()
print(text)


import string
print(string.punctuation)
# Remove punctuation
text_p = "".join([char for char in text if char not in string.punctuation])
print(text_p)

# Tokenization
#Strings can be tokenized into tokens via nltk.word_tokenize.
import nltk
nltk.download('punkt')
words = word_tokenize(text_p)
sentences = sent_tokenize(text_p)

print(words)
print(sentences)

# Remove stopwords
from nltk.corpus import stopwords
stop_words = stopwords.words('english')
filtered_words = [word for word in words if word not in stop_words]

print(filtered_words)

# Stemming
#We stem the tokens using nltk.stem.porter.PorterStemmer to get the stemmed tokens.
from nltk.stem.porter import PorterStemmer
porter = PorterStemmer()
stemmed = [porter.stem(word) for word in filtered_words]

print(stemmed)

# Part-of-Speech Tagging Lastly, we can use nltk.pos_tag to retrieve the part of speech of each token in a list.


import nltk
nltk.download('averaged_perceptron_tagger')

pos = pos_tag(filtered_words)

print(pos)

# Conclusion:
# Text preprocessing is an important first step for any NLP application.
# This notebook covers several key preprocessing techniques using NLTK:
# 1. Lowercasing
# 2. Removing punctuation
# 3. Tokenization
# 4. Stopword filtering
# 5. Stemming
# 6. Part-of-speech tagging
